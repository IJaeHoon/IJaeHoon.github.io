<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>[AI] 8/2 실습</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-interactiveBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="67bf6369-8f25-4234-91be-f049be26ec28" class="page sans"><header><h1 class="page-title">[AI] 8/2 실습</h1><p class="page-description"></p></header><div class="page-body"><p id="bca2c167-4073-49a3-a9c5-96602194f796" class="">
</p><p id="2c357824-f47a-4ff4-a323-02c5ed78aba3" class="">
</p><h1 id="e1f770b3-1401-4da3-8ffc-f988dcdfaad7" class="">SeSAC - 파이썬 데이터 처리 프로그래밍 2일차</h1><p id="b9769d70-39d2-4ae3-b80b-2e7118b5d394" class="">2023.08.01</p><p id="27b142f5-2831-41e4-bd58-16e35ab45a5e" class="">&lt;br&gt;</p><h3 id="115d78b2-f80c-433f-9735-89895ac484e5" class="">실습 - 지식인에서 파이썬 검색해서 제목과 링크 가져오기</h3><pre id="7efc7208-ecc5-457c-9d8c-ff5b378915d4" class="code code-wrap"><code>import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup

ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

res = requests.get(&quot;&lt;https://search.naver.com/search.naver?where=kin&amp;sm=tab_jum&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&gt;&quot;, headers=headers)

bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)
area = bs.select_one(&quot;.lst_total&quot;)
# area = bs.select_one(&quot;.lst_total._list&quot;) # 두가지 클래스명을 다 가진것을 가져올때
elem = area.select(&quot;.question_text&quot;)

for e in elem:
    print(e.text)
    print(e.attrs[&quot;href&quot;])
</code></pre><p id="2c7a15fc-e0ae-41b7-846b-61ee391f7475" class="">&lt;br&gt;</p><h3 id="e1582026-025e-4e42-80c3-02cccf607538" class="">pagenation을 이용해서 여러 페이지 크롤링하기</h3><p id="107cf47b-f87e-4b31-acdd-7a44a22bd99a" class="">네이버에서 파이썬을 검색한 첫번째 페이지의 주소를 확인해보자.</p><p id="fd37bf7c-96df-4309-b92c-00219176daad" class=""><a href="https://github.com/kimbap918/TIL/assets/75712723/4af4a623-7652-437a-8863-8b99283a8e57">https://github.com/kimbap918/TIL/assets/75712723/4af4a623-7652-437a-8863-8b99283a8e57</a></p><p id="08144d4d-2faa-41ce-9a48-0d9f8edd9ca4" class="">페이지의 주소는 아래와 같다.</p><pre id="5cc63b80-de2c-4c46-b20e-55ef94cd2aec" class="code code-wrap"><code># kin_start=1
&lt;https://search.naver.com/search.naver?where=kin&amp;kin_display=10&amp;qt=&amp;title=0&amp;&amp;answer=0&amp;grade=0&amp;choice=0&amp;sec=0&amp;nso=so%3A-1%2Ca%3A%2Cp%3Aall&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;c_id=&amp;c_name=&amp;sm=tab_pge&amp;kin_start=1&amp;kin_age=0&gt;
</code></pre><p id="f0325328-d401-4aef-b7c5-83311e3a170d" class="">그렇다면 두번째 페이지도 확인해보자.</p><p id="7bad33b4-7f5e-44b6-8c89-ef13d5155e13" class=""><a href="https://github.com/kimbap918/TIL/assets/75712723/b1dcb530-e10a-497b-8659-0e80430296d1">https://github.com/kimbap918/TIL/assets/75712723/b1dcb530-e10a-497b-8659-0e80430296d1</a></p><pre id="e21fd1ad-821b-48d6-8589-b3a7d12d33e4" class="code code-wrap"><code># kin_start=11
&lt;https://search.naver.com/search.naver?where=kin&amp;kin_display=10&amp;qt=&amp;title=0&amp;&amp;answer=0&amp;grade=0&amp;choice=0&amp;sec=0&amp;nso=so%3A-1%2Ca%3A%2Cp%3Aall&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;c_id=&amp;c_name=&amp;sm=tab_pge&amp;kin_start=11&amp;kin_age=0&gt;
</code></pre><p id="951a03b2-715c-4a6b-9618-9384d9359c72" class="">페이지가 증가함에 따라 kin_start가 10씩 증가한다.</p><p id="f486b496-50a8-4858-879e-fcfd5ef6e8cf" class="">이것을 이용해서 여러 페이지를 한번에 크롤링 할 수 있다.</p><p id="241a457c-c194-4fb5-817a-88489352d9ac" class="">&lt;br&gt;</p><h3 id="a2656030-eff4-4c50-b8ad-8bd6457052bb" class="">여러 페이지 크롤링</h3><pre id="9a43fe31-8ddd-4cf3-808e-c35d75b833fb" class="code code-wrap"><code>import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup

ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

# 크롤링 하려는 페이지의 url
url = &quot;&lt;https://search.naver.com/search.naver?where=kin&amp;kin_display=10&amp;qt=&amp;title=0&amp;&amp;answer=0&amp;grade=0&amp;choice=0&amp;sec=0&amp;nso=so%3A-1%2Ca%3A%2Cp%3Aall&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;c_id=&amp;c_name=&amp;sm=tab_pge&amp;kin_start=1&amp;kin_age=0&gt;&quot;

# 크롤링 페이지의 수
for page in range(3):
		# 페이지를 계산
    request_url = f&quot;{url}&amp;kin_display=10&amp;kin_start={(page*10)+1}&quot;
    res = requests.get(url, headers=headers)
    bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)

    area = bs.select_one(&quot;.lst_total&quot;)
    elem = area.select(&quot;.question_text&quot;)

    for e in elem:
        print(e.text)
        print(e.attrs[&quot;href&quot;])
</code></pre><p id="3accc3fa-5110-40f4-b401-532a056a7160" class="">&lt;br&gt;</p><h3 id="f3080b5f-6b1c-4295-8e45-0c2bb4e0131c" class="">pymysql</h3><p id="ceb2de25-4023-4f11-b19b-cc8d932d31ed" class="">jupyter에서 mysql 실행하기</p><pre id="6af94653-8638-40aa-94ea-e8abf17a0295" class="code code-wrap"><code>import pymysql

db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;market_db&quot;)
cursor = db.cursor() # cursor로 sql 쿼리를 가져온다.

sql = &quot;&quot;&quot;
SELECT * FROM member;
&quot;&quot;&quot;

cursor.execute(sql) # 커서 실행
result = cursor.fetchmany(size=100) # fetchone = 하나만, fetchmany = 여러개
for data in result:
    print(data)

db.close()
</code></pre><p id="fc92ec0c-d38e-4131-8229-f7d835dda1c0" class="">&lt;br&gt;</p><h3 id="64aaa9c5-7f69-441a-b54c-0189583e0b48" class="">값 삽입하기</h3><pre id="a7c44064-e3eb-4913-ab75-253261e8b417" class="code code-wrap"><code>import pymysql

db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;market_db&quot;)
cursor = db.cursor()

sql = &quot;&quot;&quot;
insert into member values(&quot;ABC&quot;, &quot;에이비씨&quot;, &quot;10&quot;, &#x27;경기&#x27;, &#x27;031&#x27;, &#x27;11122233&#x27;, &#x27;170&#x27;, &#x27;2023-08-01&#x27;);
&quot;&quot;&quot;

cursor.execute(sql)

db.commit()
db.close()
</code></pre><p id="0365d415-6c40-4b3b-badd-d8d84a2ff3fd" class="">&lt;br&gt;</p><h3 id="0a9df314-7801-4a8b-a1b8-95b8bc97e133" class="">테이블 생성해서 값 삽입해보기</h3><ol type="1" id="be74e312-1d37-4d6d-90fd-64eb911247d9" class="numbered-list" start="1"><li>sba 스키마 생성 후 아래와 같이 테이블 생성</li></ol><figure id="78a13886-b132-4a47-968e-12dc3c9a39a1" class="image"><a href="https://github.com/kimbap918/TIL/assets/75712723/e9d10e67-48e7-4aaf-ad8c-58387105697c"><img src="https://github.com/kimbap918/TIL/assets/75712723/e9d10e67-48e7-4aaf-ad8c-58387105697c"/></a></figure><ol type="1" id="60c261f5-01b5-4885-a289-8ccf88a4d2a3" class="numbered-list" start="1"><li>jupyter에서 값 삽입</li></ol><pre id="6c982127-c5b4-480a-92cd-9e4448415355" class="code code-wrap"><code>import pymysql

db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;sba&quot;)
cursor = db.cursor()

sql = &quot;&quot;&quot;
insert into link
values(NULL, &#x27;title-test&#x27;, &#x27;link-test&#x27;, &#x27;keyword-test&#x27;, &#x27;content-test&#x27;, 0, &#x27;2022-12-12&#x27;, &#x27;2023-08-01 00:00:00&#x27;);
&quot;&quot;&quot;

cursor.execute(sql)

db.commit()
db.close()
</code></pre><p id="d6b5e5ba-b0bf-444b-bd82-a33ec3d747b2" class="">&lt;br&gt;</p><h3 id="34526b13-c89e-4cec-b37d-3fdc4e9f3972" class="">실습 - 파이썬 뉴스 크롤링해서 DB에 넣기</h3><pre id="e5bf6f61-bef7-4ced-a8eb-224e1f81f3e7" class="code code-wrap"><code># 파이썬 뉴스 5페이지까지 수집
# title = 뉴스 제목, link = 뉴스의 링크, keyword = 검색어, 파이썬, content = 요약내용, count = 요약 내에서 키워드가 들어간 횟수
# date = 안넣어도됨, timestamp = now()

import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
import pymysql

db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;sba&quot;)
cursor = db.cursor()

ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

# 파이썬 뉴스 페이지
url = &quot;&lt;https://search.naver.com/search.naver?where=news&amp;sm=tab_pge&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;sort=0&amp;photo=0&amp;field=0&amp;pd=0&amp;ds=&amp;de=&amp;cluster_rank=62&amp;mynews=0&amp;office_type=0&amp;office_section_code=0&amp;news_office_checked=&amp;nso=so:r,p:all,a:all&gt;&quot;

# 5페이지를 가져오기 위해 range(5)
for page in range(5):
  	# url 뒤에 페이지 계산
    request_url = f&quot;{url}&amp;start={(page*10)+1}&quot;
    res = requests.get(request_url, headers=headers)
    bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)

    # 필요한 정보가 있는 태그 클래스
    area = bs.select_one(&quot;.list_news&quot;)
    elem = area.select(&quot;.news_area&quot;)


    for e in elem:
      	# 제목의 정보를 텍스트로, DB에 삽입 시 작은따옴표가 오류가 생겨서 큰 따옴표로 치환
        title = e.select_one(&quot;.news_tit&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
        # 제목의 정보에서 href 링크를 저장
        link = e.select_one(&quot;.news_tit&quot;).attrs[&quot;href&quot;]
        # 키워드는 파이썬
        keyword = &quot;파이썬&quot;
        # elem 내의 .dsc_txt_wrap 클래스 정보를 텍스트로, 작은따옴표 오류가 생겨서 큰 따옴표로 치환
        content = e.select_one(&quot;.dsc_txt_wrap&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
        # 컨텐츠 내의 파이썬 단어 개수를 저장
        cnt = content.count(keyword)

        sql = f&quot;&quot;&quot;
        insert into link
        values(NULL, &#x27;{title}&#x27;, &#x27;{link}&#x27;, &#x27;{keyword}&#x27;, &#x27;{content}&#x27;, {cnt}, NULL, now());
        &quot;&quot;&quot;
        cursor.execute(sql)

db.commit()
db.close()
</code></pre><p id="baeca2c2-a844-442c-8bc9-8989f3047998" class="">&lt;br&gt;</p><h3 id="e8b063aa-52ca-4adb-a930-3abee0818c7e" class="">실습 - 뉴스 기사를 모두 방문해서 &quot;파이썬&quot;이 들어간 개수 확인하기</h3><ul id="66ce6951-f139-4af7-b736-084a995ea7aa" class="bulleted-list"><li style="list-style-type:disc">작성한 답안</li></ul><pre id="18198428-7ec2-4dac-bd0d-746cdab9cdc4" class="code code-wrap"><code>import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
import pymysql

db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;sba&quot;)

ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

url = &quot;&lt;https://search.naver.com/search.naver?where=news&amp;sm=tab_pge&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;sort=0&amp;photo=0&amp;field=0&amp;pd=0&amp;ds=&amp;de=&amp;cluster_rank=62&amp;mynews=0&amp;office_type=0&amp;office_section_code=0&amp;news_office_checked=&amp;nso=so:r,p:all,a:all&gt;&quot;
cursor = db.cursor()

for page in range(2):
    request_url = f&quot;{url}&amp;start={(page*10)+1}&quot;
    res = requests.get(request_url, headers=headers)
    bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)

    area = bs.select_one(&quot;.list_news&quot;)
    elem = area.select(&quot;.news_area&quot;)

    for e in elem:

        title = e.select_one(&quot;.news_tit&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
        link = e.select_one(&quot;.news_tit&quot;).attrs[&quot;href&quot;]
        # 링크 안에 있는 내용을 읽어오기
        res2 = requests.get(link, headers=headers)
        bs2 = BeautifulSoup(res2.text, &#x27;html.parser&#x27;)
        content = bs2.select_one(&quot;html&quot;).text

        keyword = &quot;파이썬&quot;
        cnt = content.count(keyword)

        sql = f&quot;&quot;&quot;
        insert into link
        values(NULL, &#x27;{title}&#x27;, &#x27;{link}&#x27;, &#x27;{keyword}&#x27;, &#x27;{content}&#x27;, {cnt}, NULL, now());
        &quot;&quot;&quot;
        cursor.execute(sql)

db.commit()
db.close()

</code></pre><ul id="923b4d9b-c653-4296-9978-6c52cb412b39" class="bulleted-list"><li style="list-style-type:disc">풀이</li></ul><pre id="b12a1b52-6308-4513-a4e5-a0c5a9ab3ae4" class="code code-wrap"><code># 파이썬 뉴스 5페이지까지 수집
# title = 뉴스 제목, link = 뉴스의 링크, keyword = 검색어, 파이썬, content = 요약내용, count = 요약 내에서 키워드가 들어간 횟수
# date = 안넣어도됨, timestamp =

import requests
import time
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
import pymysql

db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;sba&quot;)

ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

url = &quot;&lt;https://search.naver.com/search.naver?where=news&amp;sm=tab_pge&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;sort=0&amp;photo=0&amp;field=0&amp;pd=0&amp;ds=&amp;de=&amp;cluster_rank=62&amp;mynews=0&amp;office_type=0&amp;office_section_code=0&amp;news_office_checked=&amp;nso=so:r,p:all,a:all&gt;&quot;
cursor = db.cursor()

for page in range(2):
    request_url = f&quot;{url}&amp;start={(page*10)+1}&quot;
    res = requests.get(request_url, headers=headers)
    bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)

    area = bs.select_one(&quot;.list_news&quot;)
    elem = area.select(&quot;.news_area&quot;)

    for e in elem:

        title = e.select_one(&quot;.news_tit&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
        link = e.select_one(&quot;.news_tit&quot;).attrs[&quot;href&quot;]
        keyword = &quot;파이썬&quot;

        # 링크 안에 있는 내용을 읽어오기
        res2 = requests.get(link, headers=headers)
        content = res2.text
        cnt = content.count(keyword)

        sql = f&quot;&quot;&quot;
        insert into link
        values(NULL, &#x27;{title}&#x27;, &#x27;{link}&#x27;, &#x27;{keyword}&#x27;, &#x27;{content}&#x27;, {cnt}, NULL, now());
        &quot;&quot;&quot;
        cursor.execute(sql)
        time.sleep(0.1)

db.commit()
db.close()

</code></pre><p id="d4eace5a-8b6a-4d21-abcc-5821bf11e2f0" class="">&lt;br&gt;</p><h3 id="ad940b03-88bd-4bb4-8569-95b48d10e880" class="">openpylx로 엑셀 파일 조작하기</h3><p id="8afd51ef-15ad-48de-8b9f-184bd9e622f9" class=""><a href="https://openpyxl.readthedocs.io/en/stable/">https://openpyxl.readthedocs.io/en/stable/</a></p><ul id="4fda3b42-02b0-419a-804d-6d5f10717da5" class="bulleted-list"><li style="list-style-type:disc">쓰기</li></ul><pre id="75aff299-1631-4beb-a44d-346e27163ca6" class="code code-wrap"><code>from openpyxl import Workbook

wb = Workbook()
ws = wb.active

for row in range(10):
    ws.append([row, f&quot;{row}-data&quot;])

# A1 셀에 Test-data 삽입
ws[&quot;A1&quot;] = &quot;Test-data&quot;
wb.save(&quot;result.xlsx&quot;)
</code></pre><p id="f1994993-a7ec-4136-8305-ccec5ee00791" class="">&lt;br&gt;</p><ul id="991db05f-95a6-47cc-812a-c6f4ac1a5324" class="bulleted-list"><li style="list-style-type:disc">읽기</li></ul><pre id="f5c8ebdf-2259-455e-9524-feb2bf464cb5" class="code code-wrap"><code>from openpyxl import load_workbook

wb = load_workbook(&quot;result.xlsx&quot;)
ws = wb.active

for row in ws.iter_rows():
    print(row[0].value, row[1].value)
</code></pre><p id="b7dace1a-9721-441f-8677-14f79e288a24" class="">&lt;br&gt;</p><h3 id="9d8f481f-86e4-43cb-9572-63e75977410b" class="">실습 - 뉴스 기사 엑셀 파일로 저장하기</h3><pre id="b9c3fcb7-bc35-4406-858a-f322eb27be20" class="code code-wrap"><code># DB관련 내용 삭제후 result.xlsx에 동일한 내용을 저장하도록 변경하기

import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
from openpyxl import Workbook

wb = Workbook()
ws = wb.active

ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

url = &quot;&lt;https://search.naver.com/search.naver?where=news&amp;sm=tab_pge&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;sort=0&amp;photo=0&amp;field=0&amp;pd=0&amp;ds=&amp;de=&amp;cluster_rank=62&amp;mynews=0&amp;office_type=0&amp;office_section_code=0&amp;news_office_checked=&amp;nso=so:r,p:all,a:all&gt;&quot;

for page in range(2):
    request_url = f&quot;{url}&amp;start={(page*10)+1}&quot;
    res = requests.get(request_url, headers=headers)
    bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)

    area = bs.select_one(&quot;.list_news&quot;)
    elem = area.select(&quot;.news_area&quot;)

    for e in elem:

        title = e.select_one(&quot;.news_tit&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
        link = e.select_one(&quot;.news_tit&quot;).attrs[&quot;href&quot;]
        keyword = &quot;파이썬&quot;

        # 링크 안에 있는 내용을 읽어오기
        res2 = requests.get(link, headers=headers)
        content = res2.text
        cnt = content.count(keyword)

        # 제목, 링크, 키워드, 내용, 카운트
        ws.append([title, link, keyword, content, cnt])

# result.xlsx로 저장
wb.save(&quot;result.xlsx&quot;)

</code></pre><p id="53980900-2661-4877-9cf3-1d6c4c18b294" class="">&lt;br&gt;</p><h3 id="fab0fd9e-5ebc-4465-9093-148c5ae916b8" class="">실습 - 멜론 데이터 가져와서 DB에 삽입, Excel에 저장하기</h3><ul id="f083f96f-2d37-4190-820e-3f3b78653b67" class="bulleted-list"><li style="list-style-type:disc">순위, 제목, 가수, 앨범, 좋아요, 변동 넣어보기</li></ul><p id="9c8abd4a-1370-4b9b-9bd1-0907ea46fbff" class="">테스트 데이터 DB에 넣어보기</p><pre id="609c40c0-7316-4af3-b9b0-022bdaad6661" class="code code-wrap"><code># 순위, 제목, 가수, 앨범, 좋아요

import pymysql

# 테스트 데이터 넣어보기
db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;sba&quot;)
cursor = db.cursor()

sql = &quot;&quot;&quot;
insert into melon
values(NULL, 101, &quot;바보&quot;, &quot;최준혁&quot;, &quot;최준혁2집&quot;, -1, -100);
&quot;&quot;&quot;

cursor.execute(sql)

db.commit()
db.close()
</code></pre><p id="0cf18af8-2a04-4962-82bf-e09712e26f67" class="">&lt;br&gt;</p><ul id="d23d32a0-79f8-4436-b9d7-cf61948826ae" class="bulleted-list"><li style="list-style-type:disc">크롤링 및 DB삽입</li></ul><pre id="e94de2c8-5e0b-4965-821a-051902691b9d" class="code code-wrap"><code># 순위, 제목, 가수, 앨범, 좋아요
# rank, title, singer, album, like, diff
import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
from openpyxl import Workbook
import pymysql

# 5. DB 연결 설정
db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;sba&quot;)
cursor = db.cursor()

# 8. workbook
wb = Workbook()
ws = wb.active

# 1. userAgent
ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

# 2. 가져올 url
url = &quot;&lt;https://www.melon.com/chart/index.htm&gt;&quot;
res = requests.get(url, headers=headers)
bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)

# 3. 가져올 정보 클래스
area = bs.select_one(&quot;.service_list_song&quot;)
elem = area.select(&quot;div &gt; table &gt; tbody &gt; tr&quot;)

# 4. 순위, 제목, 가수, 앨범, 좋아요
for e in elem:
    rank = e.select_one(&quot;.rank&quot;).text
    title = e.select_one(&quot;.ellipsis.rank01 &gt; span &gt; a&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;) # replace는 DB insert 시 작은따옴표 처리를 위해 사용
    singer = e.select_one(&quot;.ellipsis.rank02 &gt; a&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
    album = e.select_one(&quot;.ellipsis.rank03 &gt; a&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
    diff = e.select_one(&quot;.rank_wrap&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)

    # 6. DB에 저장
    sql = f&quot;&quot;&quot;
    insert into melon
    values(NULL, {rank}, &#x27;{title}&#x27;, &#x27;{singer}&#x27;, &#x27;{album}&#x27;, 0, &#x27;{diff}&#x27;);
    &quot;&quot;&quot;
    cursor.execute(sql)

    # 9. Excel에 저장
    ws.append([rank, title, singer, album, 0, diff])

# 7. DB commit
db.commit()
db.close()

# 10. excel 저장
wb.save(&quot;melon.xlsx&quot;)

    # print(&quot;순위 : &quot;, rank)
    # print(&quot;제목 : &quot;, title)
    # print(&quot;가수 : &quot;, singer)
    # print(&quot;앨범 : &quot;, album)
    # print(&quot;변동 : &quot;, diff)
</code></pre><p id="e65e7321-ceca-41af-874a-dd9843f96b70" class="">&lt;br&gt;</p><h3 id="dafc349d-f7c9-4be0-97c9-acca45f1c746" class="">실습2 - 순위 변동 표시하기</h3><pre id="c7b79a13-a78a-47c5-825c-a807ccda75ef" class="code code-wrap"><code># 순위 변동 추가 변동없음, - +2 -3 형태
# python 안에서 쿼리 짜서 출력
# 각 가수별로 top100에 올라간 곡 수, 가수명을 출력하고 순서대로 정렬해서 출력

import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
from openpyxl import Workbook
import pymysql

# DB
db = pymysql.connect(host=&quot;localhost&quot;, port=3306, user=&quot;root&quot;, password=&quot;jen401018&amp;&quot;, db=&quot;sba&quot;)
cursor = db.cursor()

# workbook
wb = Workbook()
ws = wb.active

# userAgent
ua = UserAgent()
headers = {
    &quot;User-Agent&quot; : ua.random
}

# 가져올 url
url = &quot;&lt;https://www.melon.com/chart/index.htm&gt;&quot;
res = requests.get(url, headers=headers)
bs = BeautifulSoup(res.text, &#x27;html.parser&#x27;)

# 가져올 정보 클래스
area = bs.select_one(&quot;.service_list_song&quot;)
elem = area.select(&quot;div &gt; table &gt; tbody &gt; tr&quot;)

# 순위, 제목, 가수, 앨범, 좋아요
for e in elem:
    rank = e.select_one(&quot;.rank&quot;).text
    title = e.select_one(&quot;.ellipsis.rank01 &gt; span &gt; a&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
    singer = e.select_one(&quot;.ellipsis.rank02 &gt; a&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
    album = e.select_one(&quot;.ellipsis.rank03 &gt; a&quot;).text.replace(&quot;&#x27;&quot;, &#x27;&quot;&#x27;)
    # 슬라이싱
    diff_icon = e.select_one(&quot;.rank_wrap&quot;).text[:6]
    diff = e.select_one(&quot;.rank_wrap&quot;).text[7]

    # 순위가 동일하면 -, 단계 상승이면 +n, 단계 하락이면 -n
    if &quot;순위 동일&quot; in diff_icon:
        diff = &quot;-&quot;
    elif &quot;단계 상승&quot; in diff_icon:
        diff = &quot;+&quot; + diff
    elif &quot;단계 하락&quot; in diff_icon:
        diff = &quot;-&quot; + diff
    else:
        diff = &quot;new&quot;
</code></pre><p id="ff6c9e48-d925-4d02-9477-71a6afeb109b" class="">&lt;br&gt;</p><h3 id="905c7047-2432-4f69-a2b0-ca0f4e27639b" class="">실습3 - python에서 쿼리 실행하기</h3><pre id="ddc53b60-a5f5-415b-b9a2-6a54fb22e7db" class="code code-wrap"><code>sql = &quot;&quot;&quot;
SELECT count(singer) 곡수, singer
FROM melon
GROUP BY singer
ORDER BY 곡수 DESC;
&quot;&quot;&quot;

cursor.execute(sql)
result = cursor.fetchmany(size=100) # fetchone = 하나만, fetchmany = 여러개
for data in result:
    print(data)
</code></pre><p id="f7efa3ff-965a-49e1-ad71-b08cd42b2df8" class="">
</p><p id="6f62e23c-0e19-46c0-b988-6b4fc3dd576a" class="">import pymysql
import time
from selenium import webdriver
from <a href="http://selenium.webdriver.common.by/">selenium.webdriver.common.by</a> import By
from selenium.webdriver.common.keys import Keys
#키값 입력 가능</p><p id="86115d58-86a4-4119-ba74-2212c862b104" class="">from selenium.webdriver.chrome.service import Service</p><p id="9d82269e-1858-47d3-8342-52bb38d05404" class="">from openpyxl import Workbook</p><p id="aa169fd1-3edb-4472-a480-a7682abd5932" class="">wb = Workbook()
ws = wb.active</p><p id="39ca0d8e-6a02-45e0-a11c-a1c401397cd5" class="">service = Service()
d = webdriver.Chrome(service=service)</p><p id="ba7b340c-7782-4582-9fc9-71beacd17247" class="">try:</p><pre id="91b740eb-0e71-48eb-8c5c-a61ebf80a2c8" class="code code-wrap"><code>#키값 입력 / 실행
d.get(&quot;&lt;https://cafe.naver.com/joonggonara&gt;&quot;)
elem = d.find_element(By.CSS_SELECTOR, &quot;#topLayerQueryInput&quot;)
elem.send_keys(&quot;자전거&quot;)
elem.send_keys(Keys.RETURN)


iframe = d.find_element(By.CSS_SELECTOR, &quot;#cafe_main&quot;)
d.switch_to.frame(iframe)


for page in range(2, 5):
    #x = d.find_element(By.CSS_SELECTOR, &quot;#main-area&quot;)
   # y = x.find_elements(By.CSS_SELECTOR, &quot;table &gt; tbody &gt; tr&quot;)

    trs = d.find_elements(By.CSS_SELECTOR, &quot;.article-board &gt; table &gt; tbody &gt; tr&quot;)
    for tr in trs:
        title = tr.find_element(By.CSS_SELECTOR, &quot;.article&quot;).text
        id = tr.find_element(By.CSS_SELECTOR, &quot;.p-nick&quot;).text
        time = tr.find_element(By.CSS_SELECTOR, &quot;.td_date&quot;).text

        print(title,id,time)
        ws.append([title, id, time])


page_area = d.find_element(By.CSS_SELECTOR, &quot;.prev-next&quot;)

page_link = page_area.find_element(By.LINK_TEXT,str(page))

page_link.click()
</code></pre><p id="310048de-26e7-4970-a392-736efaa32078" class="">except Exception as e:
print(e)</p><p id="49a70175-d73c-4e7d-a351-e68e5c504930" class="">finally:
d.close()
d.quit()</p><p id="0802c012-4cbd-4b73-8ee5-ac1c210b1b57" class="">wb.save(&quot;joonggonara.xlsx&quot;)</p><h1 id="4ae97936-a3d6-4305-8e77-cf1b6dfd465c" class="">1페이지부터 5페이지 제목 / 작성자이름 / 작성일 액셀로 뉴스기사</h1><h1 id="8ebb417c-e4d9-4033-af58-37b44e7c878b" class="">링크텍스트로 반복문, 같은 방법으로 링크텍스트 prev-next 1, 2, 3</h1><h1 id="6ee830f3-7103-4cd0-9b44-dff3f7ae3395" class="">액셀로 저장해서 코드랑 액셀 보여주면됨</h1></div></article></body></html>