 

# [AI] 8/2 메모장

셀렉트로 반환된건 리스트로 반환됨

trs로 셀렉트 반영하면 trs.text < 는 에러가난다

text는 태그가 가지고 있는 것,

★크롤링 데이터는 공백이 많음,

.strip()로 가져온거 공백 없애주는 습관

csv, , , \n << 지워줘야 의도한대로 데이터가 들어감 지워줘야함

★ API (애플리케이션 프로그래밍 인터페이스)

ㄴ브라우저 접속해서 요청하는건 똑같은데 주는 데이터가 다른 거

그래서 안주면 못 씀

(API (Application Programming Interface)란 다른 프로그램에서 사용할 수 있도록, 운영체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 있게 만든 인터페이스를 말합니다. 일반적으로 API는 개발자가 서비스를 활용하기 위해 사용할 수 있는 명령어 집합을 의미합니다. 이 명령어를 이용하여 프로그래머는 서비스에서 제공하는 데이터를 가져오거나, 데이터를 전송하거나, 기타 서비스를 조작할 수 있습니다.)

-**JSON** 홈페이지

[https://jsonplaceholder.typicode.com/](https://jsonplaceholder.typicode.com/)

제이썬 함수 ⇒ 자동으로 파이썬제공함수로 바꿔줌

- posts = res..json << 파이썬 제공 함수로 바뀐다

import requests

res = requests.get("[https://jsonplaceholder.typicode.com/posts](https://jsonplaceholder.typicode.com/posts)") posts = res.json()

for post in posts: print(post["userId"],post["title"])

어떤 문서는 웹문서가 아니라, API를 준다, 그냥 갖다쓰면됨, 주는 데이터만 다르고 주소만 다름

[![](HTML%20import/Attachments/Untitled%2010.png)](Untitled%2010.png)

if res.status_code = 200:

posts = res.json()

[인증키 디코딩]

-인코딩

8HMdBevY6FGg%2Beafe%2F8P07FamzB1PZwxtZ5c%2FeLVOVUNkJHSYFa6YxDTFxmFSHWshWWXxFJQN7Fj%2Fv%2FVt700%2BA%3D%3D

-디코딩

8HMdBevY6FGg+eafe/8P07FamzB1PZwxtZ5c/eLVOVUNkJHSYFa6YxDTFxmFSHWshWWXxFJQN7Fj/v/Vt700+A==

[8/2 날씨 API]

import requests

url = '[http://apis.data.go.kr/1360000/MidFcstInfoService/getMidFcst](http://apis.data.go.kr/1360000/MidFcstInfoService/getMidFcst)' params ={ 'serviceKey' : '8HMdBevY6FGg+eafe/8P07FamzB1PZwxtZ5c/eLVOVUNkJHSYFa6YxDTFxmFSHWshWWXxFJQN7Fj/v/Vt700+A==', 'pageNo' : '1', 'numOfRows' : '10', 'dataType' : 'JSON', 'stnId' : '108', 'tmFc' : '202308020600' }

response = requests.get(url, params=params) data = response.json() print(data)

- 안되었을때 제일 먼저 텍스트를 봐야함, 반환해줘야 할 값이 뭐가있지 보고 잘 써줘야함

import requests import pprint

url = '[http://apis.data.go.kr/1360000/MidFcstInfoService/getMidFcst](http://apis.data.go.kr/1360000/MidFcstInfoService/getMidFcst)' params ={ 'serviceKey' : '8HMdBevY6FGg+eafe/8P07FamzB1PZwxtZ5c/eLVOVUNkJHSYFa6YxDTFxmFSHWshWWXxFJQN7Fj/v/Vt700+A==', 'pageNo' : '1', 'numOfRows' : '10', 'dataType' : 'JSON', 'stnId' : '108', 'tmFc' : '202308020600' }

response = requests.get(url, params=params) data = response.json() pprint.pprint(data)

for item in data["response"] ["body"] ["items"] ["item"]: print(item["wfSv"])

ㄴ 보기편하게

- 셀레니움 , 동적 웹을 크롤링하기 위해 필요한 도구
    
    셀레니움 → 브라우저 테스트 프로그램
    

import time from selenium import webdriver from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install()) d = webdriver.Chrome(service=service) try: d.get("[https://naver.com](https://naver.com/)") except Exception as e: print(e) finally: time.sleep(2) d.close() d.quit()

# try,except,finlally = 예외처리

[![](HTML%20import/Attachments/Untitled%2011.png)](Untitled%2011.png)

get → 웹문서에 간다(이동하면 get)

d.get(”naver.com”) 네이버로가줘

import time from selenium import webdriver from [selenium.webdriver.common.by](http://selenium.webdriver.common.by/) import By

from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install()) d = webdriver.Chrome(service=service)

# try,except,finlally = 예외처리

try: d.get("[https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105](https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105)") elem = d.find_element(By.CSS_SELECTOR, "#_rankingList0") print(elem.text)

except Exception as e: print(e)

finally: time.sleep(2) d.close() d.quit()

elem = d.find_element(By.CSS_SELECTOR, "#_rankingList0") #ㄴbs4의 태그, find_element -> find_elements 는 여러개 가져오는거

import time from selenium import webdriver from [selenium.webdriver.common.by](http://selenium.webdriver.common.by/) import By

from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install()) d = webdriver.Chrome(service=service)

# try,except,finlally = 예외처리

try: d.get("[https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105](https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105)")

# elem = d.find_element(By.CSS_SELECTOR, "#_rankingList0")

# titles = elem.find_elements(By.CSS_SELECTOR, ".list.tit")

# #ㄴbs4의 태그, find_element -> find_elements 는 여러개 가져오는거

# for title in titles:

# print(title.text)

```
section = d.find_element(By.CSS_SELECTOR, ".section_body")
lis = section.find_elements(By.CSS_SELECTOR, "ul > li")
for li in lis:
    print(li.text)
```

except Exception as e: print(e)

finally: time.sleep(2) d.close() d.quit()

import time from selenium import webdriver from [selenium.webdriver.common.by](http://selenium.webdriver.common.by/) import By

from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install()) d = webdriver.Chrome(service=service)

try: d.get("[https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105](https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105)")

# elem = d.find_element(By.CSS_SELECTOR, "#_rankingList0")

# titles = elem.find_elements(By.CSS_SELECTOR, ".list.tit")

# #ㄴbs4의 태그, find_element -> find_elements 는 여러개 가져오는거

# for title in titles:

# print(title.text)

```
time.sleep(0.5)

section = d.find_element(By.CSS_SELECTOR, ".section_body")
lis = section.find_elements(By.CSS_SELECTOR, "ul > li")
for li in lis:
    print(li.text)

page_area = d.find_element(By.CSS_SELECTOR, "#paging")
page_2 = page_area.find_element(By.LINK_TEXT,"2")
page_2.click()

time.sleep(2)

section = d.find_element(By.CSS_SELECTOR, ".section_body")
lis = section.find_elements(By.CSS_SELECTOR, "ul > li")
for li in lis:
    print(li.text)
```

except Exception as e: print(e)

finally: time.sleep(2) d.close() d.quit()

import time from selenium import webdriver from [selenium.webdriver.common.by](http://selenium.webdriver.common.by/) import By

from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install()) d = webdriver.Chrome(service=service)

try: d.get("[https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105](https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105)")

```
time.sleep(2)


for page in range(2,6):

# 뉴스 찾아오는 명령어
    section = d.find_element(By.CSS_SELECTOR, ".section_body")
    lis = section.find_elements(By.CSS_SELECTOR, "ul > li")
    for li in lis:
        print(li.text)


# 클릭을 해주는 명령어
    page_area = d.find_element(By.CSS_SELECTOR, "#paging")
    page_link = page_area.find_element(By.LINK_TEXT, str(page))
    page_link.click()

    time.sleep(2)
    print("-"*30, page,"-"*30)
```

except Exception as e: print(e)

finally: time.sleep(2) d.close() d.quit()

[![](HTML%20import/Attachments/Untitled%2012.png)](Untitled%2012.png)

- SELECT * FROM sba.melon;

- truncate table sba.melon;

ㄴ SQL 데이터 저장

[![](HTML%20import/Attachments/Untitled%2013.png)](Untitled%2013.png)

for page in range(2, 7):

page_area = d.find_element(By.CSS_SELECTOR, “.prev-next”)

page_link = page_area.find_element(By.LINK_TEXT,str(page))

page_link.click()

[https://pypi.org/project/pymysql/](https://pypi.org/project/pymysql/)

[](https://www.notion.soundefined)