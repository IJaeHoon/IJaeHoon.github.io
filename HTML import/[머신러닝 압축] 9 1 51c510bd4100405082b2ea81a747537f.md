 

# [머신러닝 압축] 9/1

얀 르쿤, 이미지 인식 사람, 가로 세로로 계산하는거 아닐까 생각

허준희 필즈상 받아도 정식교수아니었음 , 페르마 마지막 정리 푼 사람도 못받은, 재수떼기

하드웨어의 발전은 소프트웨어의 발전없이 발전할 수 없어

소프트웨어를 쓸려고 사는거

sun 썬이란 회사, 하드웨어회사 썬마이크로시스템즈 > 지금은 썬 오라클에 통합되었음

제임스 고 슬링 < 썬에 근무하던 엔지니어, ‘자바’ 만듦 자바 키트 오라클로감,

썬이 만든 영화 → 터미네이터 그 당시 환상이었던 그래픽 < 실리콘 그래픽스씀 < 만든게 썬마이크로시스템즈

엣지디텍션필터 > 사람이 만듦, -1 0 1 ~ → 이걸 얀르쿤이 기계가 만들게 함, 딥러닝 이용

기계한테 개 사진을 주고 개의 특징을 찾는 필터를 만들라고 했음

ㄴ 그 특징 찾기위해 맨땅에 헤딩, 딥러닝 = 맨 땅에 헤딩, 필터가 뭘 강조하는지 우린 모름

ㄴ 근데 잘 됨, 어쨌든 레이블을 맞추고 있는 것

컨볼루션 = 행렬의 곱 연산을 보고 컨볼루션이라 부름

☆심화

‘필터’

히든레이어의 활성화함수는 렐루함수로 거의 고정

피쳐맵 → 특징맵

엣징된 이미지,

피쳐맵을 통과한 것 → 렐루한것

코를 강조하는 필터면 코만 밝은 색으로 변경,

얀르쿤은 저게 서브샘플링이라고했음 이후에 사람들은 저걸 fooling이라고 함

maxfooling을 많이 쓴다

mnist

vgg16 16층

선명

컴볼루션레이어 → 피쳐

결과물 → 클라스피케이션

캐라스는 너무 고도화되어 쓰기가 어려움,

파이토치가 들여다보면 더 덜 고도화되어있음,

‘파이토치’ 강좌 봐두면 도움이 될 것,

# 프랑소와 숄레 - 박해선 번역

ㄴ딥러닝만 포커스를 맞춘 책

[![](HTML%20import/Attachments/Untitled%2063.png)](Untitled%2063.png)

- 바닐라 CNN 가장 기본적인 CNN 기초 구조

[![](HTML%20import/Attachments/Untitled%2064.png)](Untitled%2064.png)

★ 노드의 수를 늘이면 샘플의 수를 늘인 효과가 나타나나

100개보단 4000개 이상

입력되는 입력값의 수보다 노드의 수가 많아야한다

3060몇개 나옴 입력값, ← 노드 4천개 이상이 좋다!

한 레이어에 1개의 인풋값보다 노드값이 더 크면 좋음

노드의 갯수가 뭐가 그리 중요해 ← 노드보다 레이어가 많은게 더 좋아 / 노드는 레이어 수 보다 적은건 상관없는데, ← 인풋의 수가 노드 수보단 적은게 좋아

플래튼 한 다음 노드 수가 인풋보다 높은게 나음< 근데 이건 꼼수고 레이어 수 늘리는게 맞겠지, 풀링 너무 여러번하면, 0이 나옴 2x2 풀링하면